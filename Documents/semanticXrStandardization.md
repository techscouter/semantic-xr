# Semantic-XR Standardization

This page describes how the Semantic-XR format could be used in the future as part of the standardization of XR Accessibility (“XR” in the broad sense of **any** 3D or 4D media). It describes a way to define conformance levels, similar to the W3C WCAG’s A, AA and AAA conformance levels and in addition, before that and importantly, it describes a long list of communities that will benefit from this standardization and how they will benefit from it.

## "What’s in it for me?": Communities that Could Benefit from Semantic-XR Standardization

Let’s go over how the usage and the standardization of the Semantic-XR format will assist many communities and through that learn about the format's strengths:

* **For people with disabilities:** the potential of more than one billion people with disabilities to participate in XR Experiences via a large variety of new compatible Accessibility Solutions for many kinds of disabilities. Accessibility Solutions that would provide them the agency and options to choose where, when and how to explore the 3D environments in the XR Experiences.
* **For people with disabilities:** this solution is generic enough to support XR (VR, AR, MR) but also any 3D or 4D content, not only what is usually categorized under 'XR'. For example: movies, animation films, video games, 3D models, CAD (Computer Aided-Design) content, images with 3D content, sketches with 3D content, real life photos and videos and live streams and generative AI content (via training and inference in real-time) and more...
* **For people with disabilities:** ability to create XR Experiences and XR Accessibility Solutions for themselves and for others (solves a major obstacle - accessible XR content is a big enabler for XR content authoring).
* **For people with disabilities:** ability to provide extensive support for a large variety of disabilities: vision, hearing, cognitive, motor.
* **For people with motor disabilities:** this XR Accessibility solution proposal includes an initial potential solution for a long standing challenge: Universal Controller Mapping. The Universal Controller Mapping infrastructure idea is discussed separately in a dedicated section in the High Impact Experimental Ideas page.
* **Accessibility Solutions Creators:** widespread support for their solution which would work with any XR Experience that supports the required schemaVersion(s): Ability to provide extensive support for a large variety of disabilities, Personalization, Ease of use, Flexibility, Extensibility (via Semantic-XR built-in format hooks and different schemaVersions) and more.
* **Traditional Accessibility Solutions providers:** ability to extend their tools to support XR and 3D and 4D content (for example screen readers that would be able to add scans of 3D scenes with spatial audio similar to traversing a list of headers on a web page or another example would be providing lists of different types of entities like people or locations).
* **New Accessibility Solutions providers:** ability to build solutions in a variety of ways: as game engines plugins, game engines built-in support, browsers plugins, browsers built-in support, Operating System level solutions (mobile\ desktop\ tablet\ laptop\ TV\ XR headsets etc.) or as part of the XR Experience itself using reusable or custom Accessibility Solutions.
* **XR Accessibility Solutions Researchers:** Semantic-XR enables easy prototyping without requiring access to the content via inaccessible and complex authoring software. This could be leveraged by accessibility researchers and consultants including people with disabilities that would prototype and build their own solutions that could then be made into reusable Accessibility Solutions. A researched, tested and verified easy-to-build browser extension can make its way to the browser, to a game engine plugin, into a video game and maybe even to the Operating System itself.
* **Creators of XR Experiences:** a streamlined way to support XR Accessibility using their authoring tool (by enabling a Semantic-XR plugin, choosing the supported schemaVersions and tagging their content according to the [tagging instructions](/Implementation/semanticXrTagsBasedApproach.md)). This would enable them full creator control via the tags and supported schemaVersion over the contents of exported Semantic-XR. Once export is supported then both existing solutions can be reused and in addition customized accessibility solutions can be developed (for a specific experience or for their studio's reuse or for the entire community reuse via an open source solution).
* **Standards Organizations like the W3C:** we would have a uniform semantic metadata format for all 3D and 4D experiences (with a way to specify how these experiences relate to each other using `crossSemanticXrEquality`). Semantic-XR's `schemaVersion` field could be used like WCAG's levels of conformance - 3D and 4D content that would be Perceivable, Operable, Understandable and Robust. This could become: XCAG (“XR Content Accessibility Guidelines”). See many more details below.
* **Legal purposes:** if indeed a standard is defined then an XR Experience should support Semantic-XR's schemaVersion A or AA or AAA or other values for different levels of Accessibility Solutions support - highly simplified and familiar concept yet extremely powerful descriptive power. Similar to WCAG that requires content to be built in a specific way that can be supported by external Assistive Technology tools like a screen reader.
* **For developers of 3D and 4D tools:** once they implement a Semantic-XR plugin the content created by the tool can be made accessible using reusable Accessibility Solutions. Also making their tool accessible for people with disabilities is easier - they need to support the tool interface while the XR content is already accessible. Examples for tools that would highly benefit from this solution: Unreal Engine, Unity, WebXR web frameworks, Blender, Unreal Engine for Fortnite, Godot, OpenUSD integration and others. A roadmap for a tool developer could be to support a basic Semantic-XR schemaVersion, then allowing community Accessibility Solution plugins integration, then support advanced schemaVersions, then develop tool UX accessibility support and finally developing Accessibility Solution plugins themselves.
* **For AI specialists:** for training and for inference of Semantic-XR for real life streams\ videos\ photos and for generative AI content which becomes more and more popular. For more details see the page [Semantic-XR and AI](/Documents/semanticXrAndAI.md).
* **For Metaverse creators and participants:** an example of "solve for one, extend to many" - handling the important spatial content interoperability challenge via the semantic interoperability high impact experimental idea (discussed separately in a dedicated section in the High Impact Experimental Ideas page).
* **For all:**  additional "solve for one extend to many" opportunities. Just a few examples:
  * Analytics that leverages Semantic-XR data - for example for 3D games of sport like basketball or football etc. or VR based fitness experiences.
  * Creative web development that leverages the knowledge from the Semantic-XR format (for a concrete example check out ["Demo 3: Real World Video and Photo" video for an example of adding interactivity and interaction between a web page’s graphical shape, video and image](http://accessiblerealities.com/blog/making-3d-content-more-accessible-on-the-web-semantic-xr-proof-of-concept/)).
  * Compression - for example a Semantic-XR that includes a specific brand of a car seen in a certain location from a specific angle is a few bytes long but with proper rendering and prior knowledge can render a very high quality image of that car - enabling orders of magnitude levels of compression of media (idea discussed separately in the page about High Impact Experimental Ideas and mentioned in [my blog post from 2010 about Semantic Editing, Encoding and Decoding](https://blog.techscouter.net/techscouter/seed-semantic-editing-encoding-and-decoding)).


## Standardization: XR Accessibility Conformance Levels
`schemaVersion` is an important field of the Semantic-XR format. Below is an explanation of this field as well as a description of how it could be used to enable the definition of XR Accessibility Conformance Levels.

A specific Semantic-XR document’s schemaVersion field value describes which Semantic-XR fields are mandatory and must be included in this specific Semantic-XR document and which fields are optional. schemaVersion field’s value is not strictly a semantic versioning string but it could be a string that can describe combinations of mandatory and optional sets of fields (for example: GlobalPositionsOnly_0.1.0 or BasicWithoutImages_0.0.1 etc.). schemaVersion values would probably include a namespace component to avoid naming collisions - this might be based on using a domain-like string structure. A Semantic-XR generator (like one in a video game or a movie player) can publish its supported schemaVersions to align expectations with its clients.

schemaVersion could also be used in the future for short codes to represent agreed upon conformance levels. In a similar manner to W3C WCAG’s A, AA and AAA conformance levels for web content - a W3C XCAG (XR Content Accessibility Guidelines) standard could be defined. The new standard could include WCAG-like conformance levels based on the Semantic-XR’s schemaVersion values. For example A, AA or AAA schemaVersion field values would specify different lists of mandatory fields that should appear in the Semantic-XR metadata that would in turn enable different types and levels of Accessibility Solutions supporting multiple disabilities.